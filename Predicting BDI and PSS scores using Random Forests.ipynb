{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting BDI and PSS scores using Random Forests\n",
    "\n",
    "The Marmar paper uses Random Forests, and that made me curious about Random Forests. So I spent some time understanding what it does, and how it can be used in our context.\n",
    "\n",
    "Random forest is a type of supervised machine learning algorithm based on ensemble learning. Ensemble learning is a type of learning where you join different types of algorithms or same algorithm multiple times to form a more powerful prediction model. The random forest algorithm combines multiple algorithm of the same type i.e. multiple decision trees, resulting in a forest of trees, hence the name \"Random Forest\". The random forest algorithm can be used for both regression and classification tasks.\n",
    "\n",
    "## How the Random Forest Algorithm Works\n",
    "\n",
    "The following are the basic steps involved in performing the random forest algorithm:\n",
    "\n",
    "1. Pick N random records from the dataset.\n",
    "2. Build a decision tree based on these N records.\n",
    "3. Choose the number of trees you want in your algorithm and repeat steps 1 and 2.\n",
    "4. In case of a regression problem, for a new record, each tree in the forest predicts a value for Y (output). The final value can be calculated by taking the average of all the values predicted by all the trees in forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('spectral_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>patient_BDI</th>\n",
       "      <th>patient_PSS</th>\n",
       "      <th>mfcc_1_mean</th>\n",
       "      <th>mfcc_1_median</th>\n",
       "      <th>mfcc_1_variance</th>\n",
       "      <th>mfcc_1_standard_deviation</th>\n",
       "      <th>mfcc_2_mean</th>\n",
       "      <th>mfcc_2_median</th>\n",
       "      <th>mfcc_2_variance</th>\n",
       "      <th>...</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_median</th>\n",
       "      <th>rms_variance</th>\n",
       "      <th>rms_standard_deviation</th>\n",
       "      <th>sroll_mean</th>\n",
       "      <th>sroll_median</th>\n",
       "      <th>sroll_variance</th>\n",
       "      <th>sroll_standard_deviation</th>\n",
       "      <th>phonation_rate</th>\n",
       "      <th>speech_productivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50063</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>115.00405</td>\n",
       "      <td>119.36923</td>\n",
       "      <td>1818.6350</td>\n",
       "      <td>42.645460</td>\n",
       "      <td>-31.380527</td>\n",
       "      <td>-28.231335</td>\n",
       "      <td>817.09710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.037222</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.043817</td>\n",
       "      <td>3107.645792</td>\n",
       "      <td>2627.050781</td>\n",
       "      <td>2513764.5</td>\n",
       "      <td>1585.485522</td>\n",
       "      <td>0.653829</td>\n",
       "      <td>0.529451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50099</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>128.42497</td>\n",
       "      <td>125.70503</td>\n",
       "      <td>922.8446</td>\n",
       "      <td>30.378357</td>\n",
       "      <td>0.346590</td>\n",
       "      <td>6.390878</td>\n",
       "      <td>952.29410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064619</td>\n",
       "      <td>0.051565</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.054460</td>\n",
       "      <td>2548.309655</td>\n",
       "      <td>2239.453125</td>\n",
       "      <td>1896869.0</td>\n",
       "      <td>1377.268704</td>\n",
       "      <td>0.647931</td>\n",
       "      <td>0.543374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50126</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>139.78557</td>\n",
       "      <td>135.41430</td>\n",
       "      <td>1444.5309</td>\n",
       "      <td>38.006985</td>\n",
       "      <td>22.692330</td>\n",
       "      <td>23.906433</td>\n",
       "      <td>1232.47730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068212</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.056927</td>\n",
       "      <td>1763.386327</td>\n",
       "      <td>1367.358398</td>\n",
       "      <td>2218651.5</td>\n",
       "      <td>1489.513839</td>\n",
       "      <td>0.665017</td>\n",
       "      <td>0.503722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50063</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>154.61896</td>\n",
       "      <td>156.41885</td>\n",
       "      <td>2199.7925</td>\n",
       "      <td>46.901947</td>\n",
       "      <td>5.075056</td>\n",
       "      <td>7.128631</td>\n",
       "      <td>777.93005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.088675</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.063539</td>\n",
       "      <td>2131.311035</td>\n",
       "      <td>1528.857422</td>\n",
       "      <td>2915403.0</td>\n",
       "      <td>1707.455207</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.004938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50126</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>151.89973</td>\n",
       "      <td>157.07394</td>\n",
       "      <td>903.2893</td>\n",
       "      <td>30.054771</td>\n",
       "      <td>2.058903</td>\n",
       "      <td>5.572361</td>\n",
       "      <td>477.73828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061808</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.051275</td>\n",
       "      <td>2262.284214</td>\n",
       "      <td>1851.855469</td>\n",
       "      <td>1726863.2</td>\n",
       "      <td>1314.101686</td>\n",
       "      <td>0.866511</td>\n",
       "      <td>0.154053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SID  patient_BDI  patient_PSS  mfcc_1_mean  mfcc_1_median  \\\n",
       "0  50063          6.0          9.0    115.00405      119.36923   \n",
       "1  50099         27.0         42.0    128.42497      125.70503   \n",
       "2  50126         11.0          9.0    139.78557      135.41430   \n",
       "3  50063         11.0         17.0    154.61896      156.41885   \n",
       "4  50126          8.0          4.0    151.89973      157.07394   \n",
       "\n",
       "   mfcc_1_variance  mfcc_1_standard_deviation  mfcc_2_mean  mfcc_2_median  \\\n",
       "0        1818.6350                  42.645460   -31.380527     -28.231335   \n",
       "1         922.8446                  30.378357     0.346590       6.390878   \n",
       "2        1444.5309                  38.006985    22.692330      23.906433   \n",
       "3        2199.7925                  46.901947     5.075056       7.128631   \n",
       "4         903.2893                  30.054771     2.058903       5.572361   \n",
       "\n",
       "   mfcc_2_variance  ...  rms_mean  rms_median  rms_variance  \\\n",
       "0        817.09710  ...  0.050003    0.037222      0.001920   \n",
       "1        952.29410  ...  0.064619    0.051565      0.002966   \n",
       "2       1232.47730  ...  0.068212    0.045264      0.003241   \n",
       "3        777.93005  ...  0.104553    0.088675      0.004037   \n",
       "4        477.73828  ...  0.061808    0.038281      0.002629   \n",
       "\n",
       "   rms_standard_deviation   sroll_mean  sroll_median  sroll_variance  \\\n",
       "0                0.043817  3107.645792   2627.050781       2513764.5   \n",
       "1                0.054460  2548.309655   2239.453125       1896869.0   \n",
       "2                0.056927  1763.386327   1367.358398       2218651.5   \n",
       "3                0.063539  2131.311035   1528.857422       2915403.0   \n",
       "4                0.051275  2262.284214   1851.855469       1726863.2   \n",
       "\n",
       "   sroll_standard_deviation  phonation_rate  speech_productivity  \n",
       "0               1585.485522        0.653829             0.529451  \n",
       "1               1377.268704        0.647931             0.543374  \n",
       "2               1489.513839        0.665017             0.503722  \n",
       "3               1707.455207        0.995087             0.004938  \n",
       "4               1314.101686        0.866511             0.154053  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 22.116993333334296\n",
      "Mean Squared Error: 731.559199711351\n",
      "Root Mean Squared Error: 27.04735106644181\n"
     ]
    }
   ],
   "source": [
    "# Lets try predicting BDIs using random forest regressor\n",
    "\n",
    "# Dividing data into attributes and labels\n",
    "x = dataset.iloc[:, 3:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "# Make train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=50000, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "# Testing\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 10.703846666666665\n",
      "Mean Squared Error: 133.52586259906667\n",
      "Root Mean Squared Error: 11.555339138210815\n"
     ]
    }
   ],
   "source": [
    "# Lets try predicting PSS using random forest regressor\n",
    "\n",
    "# Dividing data into attributes and labels\n",
    "x = dataset.iloc[:, 3:].values\n",
    "y = dataset.iloc[:, 1].values\n",
    "\n",
    "# Make train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=50000, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "# Testing\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Info, and Pertinent Observations\n",
    "\n",
    "BDIs are usually in the range 0 - 63. And the official distinction is as follows:\n",
    "\n",
    "1-10: These ups and downs are considered normal  \n",
    "11-16: Mild mood disturbance  \n",
    "17-20: Borderline clinical depression  \n",
    "21-30: Moderate depression  \n",
    "31-40: Severe depression  \n",
    "over 40: Extreme depression\n",
    "\n",
    "Error seems a quite high for BDI prediction, as a score difference of 22 could make a lot of difference according to the metrics mentioned above.\n",
    "\n",
    "For PSS, the score range is 0 - 40. The error is a bit lower than BDI prediction, but still, not acceptable. Need to get better predictions for a publishable result.\n",
    "\n",
    "The high errors are probably due to these disadvantages:\n",
    "\n",
    "1. Just 12 rows in our data\n",
    "2. Maybe regression is the wrong way to go.\n",
    "\n",
    "\n",
    "\n",
    "## Future work\n",
    "\n",
    "The prediction errors are high, and these are the steps I think we should be taking next:\n",
    "\n",
    "1. Patients have been stratified, so I need to run this notebook on each bucket spearately and observe the results.\n",
    "2. Discussion with Masum also reflected that maybe making buckets for BDI and PSS would help us achieve better results. Instead of using regressor to calculate exact BDI, maybe using the Random Forest classifier to just classify low/high BDI would be a better avenue to pursue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
